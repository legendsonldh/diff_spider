{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "\n",
    "from selenium import webdriver\n",
    "#from selenium.webdriver.common.keys import Keys 键盘按键导入\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "#import re 正则表达式\n",
    "import os\n",
    "import random\n",
    "\n",
    "# 谷歌翻译模块，为我们建立目录做准备\n",
    "from googletrans import Translator\n",
    "translator = Translator(service_urls=[\n",
    "      'translate.google.cn',\n",
    "    ])\n",
    "# img_title = translator.translate(img['title']).text\n",
    "# 请求头\n",
    "headers = {\n",
    "    'Connection': 'close',\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36'\n",
    "}\n",
    "\n",
    "# 页码寻找重启函数\n",
    "def Page_Reset():\n",
    "    page_num = 'page_num.txt'\n",
    "    with open(page_num, 'w') as f:\n",
    "        f.write(\"1\")\n",
    "        f.close()\n",
    "\n",
    "# 使用Phantom.js 读取信息函数\n",
    "def Get_url(url):\n",
    "    try:\n",
    "        d.get(url)\n",
    "    except:\n",
    "        print('please wait 120 seconds')\n",
    "        # d.quit()\n",
    "        time.sleep(120)\n",
    "        d.get(url)\n",
    "        print('Connection Rest')\n",
    "    time.sleep(1)\n",
    "    sp = BeautifulSoup(d.page_source, \"html5lib\")  # html5解析网页\n",
    "    d.get('about:blank')\n",
    "    return sp                                      # 返回解析过后的网址源码\n",
    "\n",
    "# 建立一个目录\n",
    "def Create_list(filename,name):\n",
    "    if os.path.exists(filename) is True:\n",
    "        print(\"%s finder have been existed\" % name)\n",
    "    else:\n",
    "        os.mkdir(filename)\n",
    "        print(\"%s finder have been created\" % name)\n",
    "    return\n",
    "\n",
    "# 点赞数建立复杂目录\n",
    "def Create_love(base):\n",
    "    lis =[0,10,50,1000]\n",
    "    for i in range(len(lis)-1):\n",
    "        what = '%s-%s' %(lis[i],lis[i+1])\n",
    "        Love = base +'/'+ what\n",
    "        Create_list(Love,what)\n",
    "    return\n",
    "\n",
    "\n",
    "def Get_Download(url_cater,base_path):\n",
    "    # 得到网址源码，开始获取信息\n",
    "    sp = Get_url(url_cater)\n",
    "\n",
    "    # 首先遍历所有页码数\n",
    "    page_all = sp.find(\"span\", {\"class\": \"pgi zpg9 iblock\"}).text\n",
    "\n",
    "    with open('page_num.txt') as f:  # 默认模式为‘r’，只读模式\n",
    "        contents = int(f.read())  # 读取文件全部内容\n",
    "\n",
    "    # 读取页码\n",
    "\n",
    "    for page in range(contents, int(page_all) + 1):\n",
    "        end = time.clock()\n",
    "        print('程序已运行:%s'%end)\n",
    "        print('This is page:%s'%page)\n",
    "\n",
    "        # 将页码信息写入，以用重复查阅\n",
    "        page_num = 'page_num.txt'\n",
    "        with open(page_num, 'w') as f:\n",
    "            f.write(\"%s\" % page)\n",
    "            f.close()\n",
    "\n",
    "        if page == 1:\n",
    "            print('begin from 1')\n",
    "            #pass\n",
    "        else:\n",
    "            img_page = url_cater.replace(\"page=1\", \"page=%s\" % page)\n",
    "            # 开始读取不同Page的信息\n",
    "            sp = Get_url(img_page)\n",
    "\n",
    "        # 每个小图组内含信息\n",
    "        sp_group = sp.find_all('div', {\"class\": \"detail f-trans\"})\n",
    "        for group in sp_group:\n",
    "\n",
    "            # 网址信息\n",
    "\n",
    "            img_url = group.find('a', {\"class\": \"name js-name etag\"})['href']   # 图组的网址\n",
    "            Phrog_url = group.find('a', {\"class\": \"js-uname uname etag\"})['href'] # 摄影师主页\n",
    "\n",
    "            # 名字信息，并进行一些防处理：去除'/',缩短我们所用的长度\n",
    "\n",
    "            Couimg_name = group.find('a', {\"class\": \"name js-name etag\"}).text.replace('/','_')    # 图组的名字\n",
    "            Phrog_name = group.find('a', {\"class\": \"js-uname uname etag\"}).text.replace('/','_')   # 摄影师名字\n",
    "\n",
    "            finder_name = '%s_%s' % (Couimg_name[0:12], Phrog_name[0:2])      # 文件夹名字\n",
    "\n",
    "            # 根据喜欢数建立文件夹；并下载\n",
    "            love_num = int(group.find('span', {\"class\": \"js-like likeicn etag\"}).text)\n",
    "\n",
    "            # 建立文件夹\n",
    "            if 0<=love_num<=10:\n",
    "                img_path_finder = base_path + '/0-10/' + finder_name\n",
    "            elif 10<love_num<50:\n",
    "                img_path_finder = base_path + '/10-50/' + finder_name\n",
    "            elif love_num>=50:\n",
    "                img_path_finder = base_path + '/50-1000/' + finder_name\n",
    "\n",
    "            Create_list(img_path_finder,finder_name)\n",
    "\n",
    "            # 将摄影师相关信息写入，以便后期查看摄影师主页\n",
    "            Pho = img_path_finder+'/'+'Pho.txt'\n",
    "            with open(Pho, 'w') as f:\n",
    "                f.write(\"%s\" % Phrog_url)\n",
    "                f.close()\n",
    "\n",
    "            # 进入图组\n",
    "            try:\n",
    "                s = BeautifulSoup(requests.get(img_url,headers=headers).text, 'html5lib')\n",
    "            except requests.exceptions.ConnectionError:\n",
    "                print('ConnectionError -- please wait 120 seconds')\n",
    "                time.sleep(120)\n",
    "                s = BeautifulSoup(requests.get(img_url, headers=headers).text, 'html5lib')\n",
    "                print('Connection Rest')\n",
    "            time.sleep(random.uniform(0.05,0.1))\n",
    "\n",
    "            # 找到图库的所有图片\n",
    "\n",
    "            img_pic = s.find_all('div', {\"class\": \"pic-area\"})\n",
    "\n",
    "            for pic in img_pic:\n",
    "                imgs = pic.find_all('img')\n",
    "                for img_image in imgs:\n",
    "                    url = img_image['data-lazyload-src']\n",
    "                    try:\n",
    "                        r = requests.get(url, stream=True,headers=headers)\n",
    "                    except requests.exceptions.ConnectionError:\n",
    "                        print('ConnectionError -- please wait 120 seconds')\n",
    "                        time.sleep(120)\n",
    "                        r = requests.get(url, stream=True, headers=headers)\n",
    "                        print('Connection Rest')\n",
    "                    time.sleep(random.uniform(0.05,0.1))\n",
    "\n",
    "                    # 图片文件命名\n",
    "                    image_name = url.split('/')[-1]\n",
    "                    # 图片文件路径\n",
    "                    img_path = img_path_finder + '/%s' %image_name\n",
    "                    # 图片文件下载\n",
    "                    if os.path.exists(img_path) == True:\n",
    "                        print(\"pass\")\n",
    "                        #pass\n",
    "                    else:\n",
    "                        with open(img_path, 'wb') as f:\n",
    "                            for chunk in r.iter_content(chunk_size=128):\n",
    "                                f.write(chunk)\n",
    "\n",
    "                if pic == img_pic[0]:\n",
    "                    print('Saved %s the first image' % image_name)\n",
    "\n",
    "\n",
    "            print('Saved %s the end image' % image_name)\n",
    "        print('End with %s'%page_all)\n",
    "    # 页码归一\n",
    "    Page_Reset()\n",
    "\n",
    "# 定位Phantom.js 的参数设置\n",
    "service_args=[]\n",
    "#service_args.append('--load-images=no')        ## 关闭图片加载\n",
    "service_args.append('--disk-cache=yes')         ## 开启缓存\n",
    "service_args.append('--ignore-ssl-errors=true') ## 忽略https错误\n",
    "service_args.append('--ssl-protocol=any')       ## 防止网站无法解析\n",
    "# 初始化PhantomJS\n",
    "d = webdriver.PhantomJS(service_args=service_args)\n",
    "\n",
    "# 程序开始计时\n",
    "start = time.clock()\n",
    "\n",
    "# 首先来到人像页面\n",
    "url = 'http://pp.163.com/pp/#p=10&c=-1&m=3&page=1'\n",
    "html = requests.get(url).text\n",
    "sp = BeautifulSoup(html,'html5lib')\n",
    "\n",
    "# 找到二级分类\n",
    "l = sp.find('ul',{\"class\": \"m-setnav\"}).find_all('a')\n",
    "# 初始化字典\n",
    "u = []\n",
    "t = []\n",
    "del l[0],l[-2],l[-1]      # 去除头尾的：\"全部\"与\"精选\"\n",
    "\n",
    "for o in l:\n",
    "    # 大分类从这里获取\n",
    "    u.append(o['sid'])\n",
    "    t.append(o.text[0:4].strip('\\n\\t'))\n",
    "\n",
    "# 主程序，也是最大的循环\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'cid=' in l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'cid' in str(l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ui'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def j():\n",
    "    if 1 == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 'ui' \n",
    "j()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = contents+1 if (contents == 0) else contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
